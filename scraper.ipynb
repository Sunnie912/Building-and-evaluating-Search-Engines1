{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "bef5ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re \n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "5ab48b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a webdriver object and set options for headless browsing\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome('/Users/sunnie/Desktop/School/UIUC/CS410/MP2.1/chromedriver',options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9423465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses webdriver object to execute javascript code and get dynamically loaded webcontent\n",
    "def get_js_soup(url,driver):\n",
    "    driver.get(url)\n",
    "    res_html = driver.execute_script('return document.body.innerHTML')\n",
    "    soup = BeautifulSoup(res_html,'html.parser') #beautiful soup object to be used for parsing html content\n",
    "    return soup\n",
    "\n",
    "#tidies extracted text \n",
    "def process_bio(bio):\n",
    "    bio = bio.encode('ascii',errors='ignore').decode('utf-8')       #removes non-ascii characters\n",
    "    bio = re.sub('\\s+',' ',bio)       #repalces repeated whitespace characters with single space\n",
    "    return bio\n",
    "\n",
    "''' More tidying\n",
    "Sometimes the text extracted HTML webpage may contain javascript code and some style elements. \n",
    "This function removes script and style tags from HTML so that extracted text does not contain them.\n",
    "'''\n",
    "def remove_script(soup):\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "    return soup\n",
    "\n",
    "\n",
    "#Checks if bio_url is a valid faculty homepage\n",
    "def is_valid_homepage(bio_url,dir_url):\n",
    "    if bio_url.endswith('.pdf'): #we're not parsing pdfs\n",
    "        return False\n",
    "    try:\n",
    "        #sometimes the homepage url points to the same page as the faculty profile page\n",
    "        #which should be treated differently from an actual homepage\n",
    "        ret_url = urllib.request.urlopen(bio_url).geturl() \n",
    "    except:\n",
    "        return False       #unable to access bio_url\n",
    "    urls = [re.sub('((https?://)|(www.))','',url) for url in [ret_url,dir_url]] #removes url scheme (https,http or www) \n",
    "    return not(urls[0]== urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4722e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts all Faculty Profile page urls from the Directory Listing Page\n",
    "def scrape_dir_page(dir_url,driver):\n",
    "    print ('-'*20,'Scraping directory page','-'*20)\n",
    "    faculty_links = []\n",
    "    faculty_base_url = 'https://www.sjsu.edu'\n",
    "    #execute js on webpage to load faculty listings on webpage and get ready to parse the loaded HTML \n",
    "    soup = get_js_soup(dir_url,driver)    \n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if \"people\" in link.get(\"href\") or \"edu/~\" in link.get(\"href\"):\n",
    "            faculty_links.append(str(link.get('href')))\n",
    "    print ('-'*20,'Found {} faculty profile urls'.format(len(faculty_links)),'-'*20)\n",
    "    return faculty_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "eb7b8a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Scraping directory page --------------------\n",
      "-------------------- Found 18 faculty profile urls --------------------\n"
     ]
    }
   ],
   "source": [
    "dir_url = 'https://www.sjsu.edu/cs/faculty/faculty.php' #url of directory listings of CS faculty\n",
    "faculty_links = scrape_dir_page(dir_url,driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4bbcf19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "\n",
    "\n",
    "def scrape_faculty_page(fac_url,driver):\n",
    "    soup = get_js_soup(fac_url,driver)\n",
    "    homepage_found = False\n",
    "    bio_url = ''\n",
    "    bio = ''\n",
    "    profile_sec = soup.find('div', class_= 'content_wrapper')\n",
    "#     if profile_sec is not None:\n",
    "#         all_headers = profile_sec.find_all('titile')\n",
    "#         faculty_last_name = all_headers[0].get_text().lower().split()[-1] #find faculty last name\n",
    "#         faculty_first_name = all_headers[0].get_text().lower().split()[0]\n",
    "#         homepage_txts = ['University',faculty_last_name,faculty_first_name]\n",
    "#         #exceptions = ['course ','research','group','cs','mirror','google scholar']\n",
    "#         #find the homepage url and extract all text from it\n",
    "#         for hdr in all_headers:  #first find the required header\n",
    "#             if hdr.text.lower() == 'for more information':\n",
    "#                 next_tag = hdr.find_next('li')\n",
    "#                 #find <li> which has homepage url\n",
    "#                 while next_tag is not None: \n",
    "#                     cand = next_tag.find('a')\n",
    "#                     next_tag = next_tag.next_sibling  #sibling means element present at the same level\n",
    "#                     try:\n",
    "#                         cand['href']\n",
    "#                     except:\n",
    "#                         continue\n",
    "#                     cand_text = cand.string\n",
    "\n",
    "#                     if cand_text is not None and (any(hp_txt in cand_text.lower() for hp_txt in homepage_txts) and \n",
    "#                         not any(e in cand_text.lower() for e in exceptions)): #compare text to predefined patterns\n",
    "#                         bio_url = cand['href'] \n",
    "#                         homepage_found = True\n",
    "#                         #check if homepage url is valid\n",
    "#                         if not(is_valid_homepage(bio_url,fac_url)):\n",
    "#                             homepage_found = False\n",
    "#                         else:\n",
    "#                             try:\n",
    "#                                 bio_soup = remove_script(get_js_soup(bio_url,driver)) \n",
    "#                             except:\n",
    "#                                 print ('Could not access {}'.format(bio_url))\n",
    "#                                 homepage_found = False\n",
    "#                         break \n",
    "#                 if homepage_found:\n",
    "#                     #get all the text from homepage(bio)\n",
    "#                     bio = process_bio(bio_soup.get_text(separator=' ')) \n",
    "\n",
    "\n",
    "#         if not homepage_found:\n",
    "    bio_url = fac_url #treat faculty profile page as homepage\n",
    "    \n",
    "    if(soup.find('div', class_='content_wrapper')):\n",
    "        profile_sec = soup.find('div', class_= 'content_wrapper')\n",
    "        bio = process_bio(profile_sec.get_text(separator=' '))\n",
    "    elif(soup.find('div', id_='content')):\n",
    "        profile_sec = soup.find('div', id_= 'content')\n",
    "        bio = process_bio(profile_sec.get_text(separator=' '))\n",
    "    elif(soup.find('div', clss_='content_item')):\n",
    "        profile_sec = soup.find('div', class_= 'content_item')\n",
    "        bio = process_bio(profile_sec.get_text(separator=' '))    \n",
    "    elif(soup.find_all(\"p\")):\n",
    "        for para in soup.find_all(\"p\"):\n",
    "            bio = para.get_text(separator=' ') \n",
    "    else:\n",
    "        html = urllib.request.urlopen(bio_url).read()\n",
    "        print(html)\n",
    "        bio = text_from_html(html)\n",
    "        print(bio)\n",
    "    return bio_url,bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7a35d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Scraping faculty url 1/18 --------------------\n",
      "-------------------- Scraping faculty url 2/18 --------------------\n",
      "-------------------- Scraping faculty url 3/18 --------------------\n",
      "-------------------- Scraping faculty url 4/18 --------------------\n",
      "-------------------- Scraping faculty url 5/18 --------------------\n",
      "-------------------- Scraping faculty url 6/18 --------------------\n",
      "b'<HTML>\\n<!--\\n<HEAD>\\n   <META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\\n   <META NAME=\"GENERATOR\" CONTENT=\"Mozilla/4.05 [en] (X11; U; SunOS 5.5.1 sun4m) [Netscape]\">\\n   <TITLE> Dr. Suneuy Kim\\'s Home Page </TITLE>\\n</HEAD>\\n<BODY TEXT=\"#000000\" BGCOLOR=\"#FFFFCC\" LINK=\"#0000FF\" VLINK=\"#FF0000\" ALINK=\"#0000FF\">\\n<TABLE BORDER=2 CELLSPACING=2 CELLPADDING=2 HEIGHT=30 WIDTH=\"80%\">\\n<TR ALIGN=BASELINE>\\n<TD ALIGN=BASELINE WIDTH=\"12%\" HEIGHT=\"20\">\\n<P><IMG SRC=\"./images/sekim.jpg\" HEIGHT=180 WIDTH=140 ALIGN=TEXT TOP></P>\\n</TD>\\n<TD ALIGN=BASELINE HEIGHT=\"20\" WIDTH=400>\\n-->\\n<font face =\"Arial, Helvetica\" size=3> \\n<b>Dr. Suneuy Kim<b><br>\\n<hr>\\n<font face =\"Arial, Helvetica\" size=2> \\nAssociate Professor <br>\\n\\n<A HREF=\"http://www.cs.sjsu.edu\">Dept. of  Computer Science </A><br>\\n\\n<A HREF=\"http://www.sjsu.edu\">San Jose State University</A><br>\\n\\nSan Jose, CA 95192-0249 \\nE-mail: <i>firstname.lastname at sjsu dot edu</i> <br>\\n\\nOffice: MacQuarrie Hall 217 <br>\\n\\nTel: (408) 924 - 5122 &nbsp;<br>\\n\\n<font face =\"Arial, Helvetica\"  size = 2>\\n<hr>\\nFall 2021\\n<ul>\\n<li><a href = \"http://www.cs.sjsu.edu/~kim/cs151\">CS151: Object-Oriented Design </a>\\n<li><a href = \"http://www.cs.sjsu.edu/~kim/cs157a\">CS157A: Introduction to Database Management Systems </a>\\n<!--\\n<li><a href = \"http://www.cs.sjsu.edu/~kim/cs157c\">CS157C: NoSQL Database Systems </a>\\n<li><a href = \"http://www.cs.sjsu.edu/~kim/cs157a\">CS157A: Introduction to Database Management Systems </a>\\n--> \\n<li>Office Hours: MTWR 12:00 pm - 12:30 pm. Please contact the CS department for the Zoom link. \\n</ul>\\n<hr>\\nTeaching\\n<ul>\\n<li>Databases\\n <ul>\\n <li>CS157A: Introduction to Database Management Systems \\n <li>CS157B: Database Management Systems II \\n <li>CS157C: NoSQL Database Systems  \\n </ul>\\n<li>Object-Oriented Programming\\n <ul>\\n <li>CS151: Object-Oriented Design \\n <li>CS46B: Introduction to Data Structures\\n <li>CS46A: Introduction to Programming \\n </ul>\\n<li>Performance Evaluation\\n <ul> \\n <li>CS286 Performance Evaluation of Computer Systems\\n </ul>\\n</ul>\\n<hr>\\nResearch\\n<ul>\\n <li>Research Areas: NoSQL Databases, Geospatial Databases, Benchmarking, Performance Evaluaton, Computer Science Education, Object-Oriented Programming \\n <li><a href = \"./publications.html\">Publications</a> <br>\\n <li><a href = \"./students.html\">Students</a> <br>\\n</ul>\\n<hr>\\n</body>\\n</html>\\n'\n",
      "   Dr. Suneuy Kim   Associate Professor  Dept. of  Computer Science  San Jose State University San Jose, CA 95192-0249 \n",
      "E-mail: firstname.lastname at sjsu dot edu  Office: MacQuarrie Hall 217 Tel: (408) 924 - 5122   Fall 2021  CS151: Object-Oriented Design  CS157A: Introduction to Database Management Systems   Office Hours: MTWR 12:00 pm - 12:30 pm. Please contact the CS department for the Zoom link.  Teaching  Databases  CS157A: Introduction to Database Management Systems CS157B: Database Management Systems II CS157C: NoSQL Database Systems  Object-Oriented Programming  CS151: Object-Oriented Design CS46B: Introduction to Data Structures CS46A: Introduction to Programming  Performance Evaluation  CS286 Performance Evaluation of Computer Systems   Research  Research Areas: NoSQL Databases, Geospatial Databases, Benchmarking, Performance Evaluaton, Computer Science Education, Object-Oriented Programming Publications   Students     \n",
      "-------------------- Scraping faculty url 7/18 --------------------\n",
      "-------------------- Scraping faculty url 8/18 --------------------\n",
      "-------------------- Scraping faculty url 9/18 --------------------\n",
      "b'<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\\n<html><head><title>Dr. Teng Moh\\'s Home Page</title></head><body style=\"background: rgb(255, 255, 255) url(http://www.cs.sjsu.edu/~tsmoh/index_files/blue.gif) repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; color: rgb(0, 0, 0);\" alink=\"#0000ee\" link=\"#0000ee\" vlink=\"#551a8b\">\\r\\n<div align=\"center\"><br>\\r\\n<br>\\r\\n</div>\\r\\n<center>\\r\\n<h3><a name=\"Dr._Teng_Mohs_Home_Page_\"></a> Dr. Teng Moh\\'s Home Page </h3>\\r\\n</center>\\r\\n<hr> <b><br>\\r\\nTeng Moh, Ph.D.<br>\\r\\n<a href=\"http://info.sjsu.edu/web-dbgen/catalog/departments/CS.html\">Computer Science</a>&nbsp;<br>\\r\\n<a href=\"http://www.sjsu.edu/\">San Jose State University</a><br>\\r\\nSan Jose, CA 95192-0249<br>\\r\\n<br>\\r\\n<i> Tel.:&nbsp;</i>408-924-5147<i><br>\\r\\nFax:&nbsp;</i>408-924-5062 <br>\\r\\n<i> E-mail:&nbsp; </i>MyFirstName&nbsp; &lt;dot&gt; MyLastName &lt;at&gt; SJSU &lt;dot&gt; EDU <br>\\r\\n<br>\\r\\n<i> Office Hours</i>: </b><span style=\"font-weight: bold;\">TBA</span><span style=\"font-weight: bold;\"></span><span style=\"font-weight: bold;\"></span><span style=\"font-weight: bold;\"></span><br>\\r\\n<b><i> Office: </i>Zoom<i><br>\\r\\n<br>\\r\\n<br>\\r\\n</i></b>\\r\\n<hr> <b><i><br>&nbsp;Fall 2020</i></b><i style=\"font-weight: bold;\"> Courses</i><br>\\r\\n<ul>\\r\\n\\r\\n  \\r\\n  \\r\\n  \\r\\n  \\r\\n  <li><b><a href=\"teach/cs297/CS297.html\">CS297/298</a> Preparation\\r\\nfor Writing Project/Master\\'s <a href=\"http://www.sjsu.edu/cs/programs/mscs/research/guidelines/\">Writing Project</a><br>\\r\\n    </b></li>\\r\\n\\r\\n\\r\\n</ul>\\r\\n\\r\\n<br>\\r\\n<hr><br>\\r\\n<span style=\"font-style: italic;\"><span style=\"font-weight: bold;\"></span></span><br>\\r\\n<span style=\"font-style: italic;\"><br>\\r\\n</span>\\r\\n<hr><br>\\r\\n<span style=\"font-style: italic;\"><span style=\"font-weight: bold;\"></span></span><br>\\r\\n</body></html>'\n",
      "     Dr. Teng Moh's Home Page    Teng Moh, Ph.D.  Computer Science   San Jose State University San Jose, CA 95192-0249   Tel.: 408-924-5147 Fax: 408-924-5062  E-mail: MyFirstName  <dot> MyLastName <at> SJSU <dot> EDU   Office Hours : TBA  Office: Zoom      Fall 2020 Courses   CS297/298 Preparation\n",
      "for Writing Project/Master's Writing Project          \n",
      "-------------------- Scraping faculty url 10/18 --------------------\n",
      "-------------------- Scraping faculty url 11/18 --------------------\n",
      "-------------------- Scraping faculty url 12/18 --------------------\n",
      "-------------------- Scraping faculty url 13/18 --------------------\n",
      "-------------------- Scraping faculty url 14/18 --------------------\n",
      "-------------------- Scraping faculty url 15/18 --------------------\n",
      "-------------------- Scraping faculty url 16/18 --------------------\n",
      "-------------------- Scraping faculty url 17/18 --------------------\n",
      "-------------------- Scraping faculty url 18/18 --------------------\n"
     ]
    }
   ],
   "source": [
    "#Scrape homepages of all urls\n",
    "bio_urls, bios = [],[]\n",
    "tot_urls = len(faculty_links)\n",
    "for i,link in enumerate(faculty_links):\n",
    "    print ('-'*20,'Scraping faculty url {}/{}'.format(i+1,tot_urls),'-'*20)\n",
    "    bio_url,bio = scrape_faculty_page(link,driver)\n",
    "    if bio.strip()!= '' and bio_url.strip()!='':\n",
    "        bio_urls.append(bio_url.strip())\n",
    "        bios.append(bio)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "00b566f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lst(lst,file_):\n",
    "    with open(file_,'w') as f:\n",
    "        for l in lst:\n",
    "            f.write(l)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "975e0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_urls_file = 'bio_urls.txt'\n",
    "bios_file = 'bios.txt'\n",
    "write_lst(bio_urls,bio_urls_file)\n",
    "write_lst(bios,bios_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b141ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d3be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
